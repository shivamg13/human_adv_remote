{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Epoch [1/6], Step [100/600], Loss: 0.3591, Accuracy: 86.00%\n",
      "Epoch [1/6], Step [200/600], Loss: 0.1562, Accuracy: 96.00%\n",
      "Epoch [1/6], Step [300/600], Loss: 0.2355, Accuracy: 91.00%\n",
      "Epoch [1/6], Step [400/600], Loss: 0.1333, Accuracy: 96.00%\n",
      "Epoch [1/6], Step [500/600], Loss: 0.0165, Accuracy: 100.00%\n",
      "Epoch [1/6], Step [600/600], Loss: 0.0611, Accuracy: 98.00%\n",
      "Epoch [2/6], Step [100/600], Loss: 0.0447, Accuracy: 98.00%\n",
      "Epoch [2/6], Step [200/600], Loss: 0.0498, Accuracy: 98.00%\n",
      "Epoch [2/6], Step [300/600], Loss: 0.0521, Accuracy: 99.00%\n",
      "Epoch [2/6], Step [400/600], Loss: 0.1544, Accuracy: 95.00%\n",
      "Epoch [2/6], Step [500/600], Loss: 0.1421, Accuracy: 94.00%\n",
      "Epoch [2/6], Step [600/600], Loss: 0.0607, Accuracy: 98.00%\n",
      "Epoch [3/6], Step [100/600], Loss: 0.0948, Accuracy: 96.00%\n",
      "Epoch [3/6], Step [200/600], Loss: 0.0464, Accuracy: 98.00%\n",
      "Epoch [3/6], Step [300/600], Loss: 0.0373, Accuracy: 98.00%\n",
      "Epoch [3/6], Step [400/600], Loss: 0.0548, Accuracy: 97.00%\n",
      "Epoch [3/6], Step [500/600], Loss: 0.0447, Accuracy: 99.00%\n",
      "Epoch [3/6], Step [600/600], Loss: 0.0758, Accuracy: 97.00%\n",
      "Epoch [4/6], Step [100/600], Loss: 0.0636, Accuracy: 98.00%\n",
      "Epoch [4/6], Step [200/600], Loss: 0.0610, Accuracy: 98.00%\n",
      "Epoch [4/6], Step [300/600], Loss: 0.1136, Accuracy: 97.00%\n",
      "Epoch [4/6], Step [400/600], Loss: 0.0500, Accuracy: 99.00%\n",
      "Epoch [4/6], Step [500/600], Loss: 0.0396, Accuracy: 97.00%\n",
      "Epoch [4/6], Step [600/600], Loss: 0.0182, Accuracy: 99.00%\n",
      "Epoch [5/6], Step [100/600], Loss: 0.0362, Accuracy: 99.00%\n",
      "Epoch [5/6], Step [200/600], Loss: 0.1186, Accuracy: 98.00%\n",
      "Epoch [5/6], Step [300/600], Loss: 0.0852, Accuracy: 96.00%\n",
      "Epoch [5/6], Step [400/600], Loss: 0.1338, Accuracy: 95.00%\n",
      "Epoch [5/6], Step [500/600], Loss: 0.0782, Accuracy: 98.00%\n",
      "Epoch [5/6], Step [600/600], Loss: 0.0896, Accuracy: 96.00%\n",
      "Epoch [6/6], Step [100/600], Loss: 0.1022, Accuracy: 97.00%\n",
      "Epoch [6/6], Step [200/600], Loss: 0.0237, Accuracy: 99.00%\n",
      "Epoch [6/6], Step [300/600], Loss: 0.0528, Accuracy: 98.00%\n",
      "Epoch [6/6], Step [400/600], Loss: 0.0210, Accuracy: 99.00%\n",
      "Epoch [6/6], Step [500/600], Loss: 0.0387, Accuracy: 97.00%\n",
      "Epoch [6/6], Step [600/600], Loss: 0.0077, Accuracy: 100.00%\n",
      "Test Accuracy of the model on the 10000 test images: 98.88 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "import numpy as np\n",
    "\n",
    "print(\"Starting experiment...\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 6\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "DATA_PATH = 'datasets/'\n",
    "MODEL_STORE_PATH = 'trained_models/'\n",
    "\n",
    "# transforms to apply to the data\n",
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=True, transform=trans, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=False, transform=trans)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = ConvNet()\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')\n",
    "\n",
    "p = figure(y_axis_label='Loss', width=850, y_range=(0, 1), title='PyTorch ConvNet results')\n",
    "p.extra_y_ranges = {'Accuracy': Range1d(start=0, end=100)}\n",
    "p.add_layout(LinearAxis(y_range_name='Accuracy', axis_label='Accuracy (%)'), 'right')\n",
    "p.line(np.arange(len(loss_list)), loss_list)\n",
    "p.line(np.arange(len(loss_list)), np.array(acc_list) * 100, y_range_name='Accuracy', color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f782375c0b8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f78237dd2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images_np = images.cpu().numpy()\n",
    "plt.imshow(images_np[18,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 524,
   "position": {
    "height": "399px",
    "left": "1257px",
    "right": "20px",
    "top": "80px",
    "width": "318px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
